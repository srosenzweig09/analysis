[model]
input_parameters = 27
param1_n6 = jet_pt
param2_n6 = jet_eta
param3_n6 = jet_phi
param4_n6 = jet_btag
param5_n6 = boosted_pt
num_hidden_layers = 2
input_activation_function = selu
hidden_layer_nodes = 40,20
hidden_activation_function = selu
num_output_nodes = 2
output_activation_function = Softmax

[training]
optimizer = nadam
learning_rate = 0.001
num_epochs = 192
beta_1 = 0.9
beta_2 = 0.999
epsilon = 1e-07
loss_function = binary_crossentropy
batch_size = 50

[scaler]
scale_min = 20.000456,20.000225,20.000301,20.000095,20.000021,20.00003,-2.4995117,-2.4995117,-2.4995117,-2.4995117,-2.4995117,-2.4995117,-3.1415837,-3.1415837,-3.1415837,-3.1415837,-3.1415837,-3.1415837,0.0011892319,0.0011663437,0.0011281967,0.001168251,0.0012245178,0.0011119843,0.11670438,0.052839268,0.115170725
scale_max = 1568.3347,1802.4725,1529.801,1473.5216,1450.4573,1750.8777,2.4995117,2.4995117,2.4995117,2.4995117,2.4995117,2.4995117,3.1415837,3.1415837,3.1415837,3.1415837,3.1415837,3.1415837,0.9995117,0.9995117,0.9995117,0.9995117,0.9995117,0.9995117,1468.7223,1510.6097,1721.8098

